Imports & Setup

# System & utility
import os, time, shutil, itertools, warnings
warnings.filterwarnings("ignore")

# Data tools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

# Deep learning
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras import regularizers
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

sns.set_style('darkgrid')
print("Modules loaded.")

Define Helpers (Data Load & DataFrame)

def define_paths(dir):
    filepaths, labels = [], []
    for fold in os.listdir(dir):
        foldpath = os.path.join(dir, fold)
        for file in os.listdir(foldpath):
            filepaths.append(os.path.join(foldpath, file))
            labels.append(fold)
    return filepaths, labels

def define_df(files, classes):
    return pd.concat([pd.Series(files, name='filepaths'), pd.Series(classes, name='labels')], axis=1)

def split_data(tr_dir, ts_dir):
    files, classes = define_paths(tr_dir)
    df = define_df(files, classes)
    train_df, valid_df = train_test_split(df, train_size=0.8, shuffle=True, stratify=df['labels'], random_state=123)
    files, classes = define_paths(ts_dir)
    test_df = define_df(files, classes)
    return train_df, valid_df, test_df

Create Generators

def create_model_data(train_df, valid_df, test_df, batch_size):
    img_size = (224, 224)
    color_mode = 'rgb'
    ts_length = len(test_df)
    test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length % n == 0 and ts_length/n <= 80]))

    def scalar(img): return img

    tr_gen = ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)
    ts_gen = ImageDataGenerator(preprocessing_function=scalar)

    train_gen = tr_gen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,
                                           class_mode='categorical', color_mode=color_mode, shuffle=True, batch_size=batch_size)
    valid_gen = ts_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,
                                           class_mode='categorical', color_mode=color_mode, shuffle=True, batch_size=batch_size)
    test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,
                                          class_mode='categorical', color_mode=color_mode, shuffle=False, batch_size=test_batch_size)
    return train_gen, valid_gen, test_gen

Show Sample Images

def show_images(gen):
    classes = list(gen.class_indices.keys())
    images, labels = next(gen)
    plt.figure(figsize=(20, 20))
    for i in range(min(len(labels), 25)):
        plt.subplot(5, 5, i + 1)
        plt.imshow(images[i] / 255)
        plt.title(classes[np.argmax(labels[i])], color='blue')
        plt.axis('off')
    plt.show()

Load Data & Show Samples

train_dir = 'brain_tumor/Training'
test_dir = 'brain_tumor/Testing'
train_df, valid_df, test_df = split_data(train_dir, test_dir)

batch_size = 20
train_gen, valid_gen, test_gen = create_model_data(train_df, valid_df, test_df, batch_size)
show_images(train_gen)

Build Model (EfficientNetB3)

img_shape = (224, 224, 3)
class_count = len(train_gen.class_indices)

base_model = tf.keras.applications.efficientnet.EfficientNetB3(
    include_top=False, weights="imagenet", input_shape=img_shape, pooling='max')

model = Sequential([
    base_model,
    BatchNormalization(),
    Dense(256, activation='relu',
          kernel_regularizer=regularizers.l2(0.016),
          activity_regularizer=regularizers.l1(0.006),
          bias_regularizer=regularizers.l1(0.006)),
    Dropout(0.45, seed=123),
    Dense(class_count, activation='softmax')
])

model.compile(optimizer=Adamax(learning_rate=0.001),
              loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

Train Model

history = model.fit(train_gen, validation_data=valid_gen, epochs=5)

Plot Training Results

def plot_training(hist):
    plt.figure(figsize=(16, 6))
    plt.subplot(1, 2, 1)
    plt.plot(hist.history['loss'], label='Training Loss')
    plt.plot(hist.history['val_loss'], label='Validation Loss')
    plt.legend()
    plt.title('Loss Over Epochs')

    plt.subplot(1, 2, 2)
    plt.plot(hist.history['accuracy'], label='Training Accuracy')
    plt.plot(hist.history['val_accuracy'], label='Validation Accuracy')
    plt.legend()
    plt.title('Accuracy Over Epochs')
    plt.show()

plot_training(history)

Evaluate & Predict

train_score = model.evaluate(train_gen, verbose=1)
valid_score = model.evaluate(valid_gen, verbose=1)
test_score = model.evaluate(test_gen, verbose=1)

print(f"Train Accuracy: {train_score[1]*100:.2f}%")
print(f"Validation Accuracy: {valid_score[1]*100:.2f}%")
print(f"Test Accuracy: {test_score[1]*100:.2f}%")


Confusion Matrix & Classification Report

y_pred = np.argmax(model.predict(test_gen), axis=1)
y_true = test_gen.classes
class_names = list(test_gen.class_indices.keys())

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))



